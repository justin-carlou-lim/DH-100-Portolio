{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import spacy\n",
    "import nltk\n",
    "import gensim\n",
    "from collections import Counter\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justincarloulim/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (4,5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Import Dataframes\n",
    "s_script = pd.read_csv('simpsons_data/simpsons_script_lines.csv')\n",
    "s_char = pd.read_csv('simpsons_data/simpsons_characters.csv')\n",
    "s_ep = pd.read_csv('simpsons_data/simpsons_episodes.csv') \n",
    "s_loc = pd.read_csv('simpsons_data/simpsons_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_id</th>\n",
       "      <th>normalized_name</th>\n",
       "      <th>char_id</th>\n",
       "      <th>line</th>\n",
       "      <th>timestamp_in_ms</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>miss hoover</td>\n",
       "      <td>464</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "      <td>848000</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>miss hoover</td>\n",
       "      <td>464</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "      <td>856000</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>miss hoover</td>\n",
       "      <td>464</td>\n",
       "      <td>Thank you, Ralph. Very graphic. Lisa Simpson? ...</td>\n",
       "      <td>784000</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>miss hoover</td>\n",
       "      <td>464</td>\n",
       "      <td>Dear God!</td>\n",
       "      <td>803000</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>miss hoover</td>\n",
       "      <td>464</td>\n",
       "      <td>I question the educational value of this assem...</td>\n",
       "      <td>226000</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_id normalized_name  char_id  \\\n",
       "0          32     miss hoover      464   \n",
       "1          32     miss hoover      464   \n",
       "2          49     miss hoover      464   \n",
       "3          49     miss hoover      464   \n",
       "4          51     miss hoover      464   \n",
       "\n",
       "                                                line timestamp_in_ms gender  \n",
       "0  No, actually, it was a little of both. Sometim...          848000      f  \n",
       "1  I don't know. Although I'd sure like to talk t...          856000      f  \n",
       "2  Thank you, Ralph. Very graphic. Lisa Simpson? ...          784000      f  \n",
       "3                                          Dear God!          803000      f  \n",
       "4  I question the educational value of this assem...          226000      f  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe that merges both script and the character information.\n",
    "# Now, we have the gender of each character, as well as their names, the timestamp\n",
    "# of their speaking lines, and their character id.\n",
    "script = s_script[['episode_id', \n",
    "                   'timestamp_in_ms', \n",
    "                   'raw_character_text', \n",
    "                   'spoken_words', \n",
    "                   'word_count']].rename(columns = {'raw_character_text': 'name', \n",
    "                                                    'spoken_words': 'line'})\n",
    "chars = s_char.dropna().rename(columns = {'id': 'char_id'})\n",
    "script_table = script.merge(chars)\n",
    "script_table = script_table[['episode_id', 'normalized_name', 'char_id', 'line', 'timestamp_in_ms', 'gender']]\n",
    "script_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import English\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "parser = English()\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        elif type(token) != str:\n",
    "            continue\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = text.lower()\n",
    "    for char in punctuation:\n",
    "        tokens = tokens.replace(char, '')\n",
    "    tokens = tokens.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script_table['line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111314"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower and remove punctuation from each line, and put\n",
    "# Into a 2d list\n",
    "text_data = []\n",
    "for line in script_table['line']:\n",
    "    if type(line) != str:\n",
    "        continue\n",
    "    tokens = prepare_text_for_lda(line)\n",
    "    text_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_index = int(len(text_data)/4)\n",
    "text_data_quarter = text_data[: quarter_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data_quarter]\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.045*\"i\" + 0.043*\"the\" + 0.032*\"a\" + 0.027*\"to\"')\n",
      "(1, '0.026*\"okay\" + 0.014*\"gotta\" + 0.009*\"kid\" + 0.007*\"thank\"')\n",
      "(2, '0.036*\"oh\" + 0.027*\"no\" + 0.020*\"my\" + 0.020*\"im\"')\n",
      "(3, '0.061*\"you\" + 0.031*\"what\" + 0.028*\"do\" + 0.027*\"hey\"')\n",
      "(4, '0.022*\"uh\" + 0.008*\"a\" + 0.008*\"cool\" + 0.007*\"um\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
